#!/usr/bin/env python3
"""
Final demonstration of Indeed scraper system functionality.
"""

import asyncio
import sys
import os

# Add the app directory to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app'))

from scrapers.indeed import IndeedScraper
from scrapers.base import ScrapingConfig, ScraperManager, JobData
from scrapers.utils import (
    validate_job_data, 
    calculate_job_relevance_score,
    location_normalizer,
    skill_extractor
)

def print_banner():
    """Print a nice banner."""
    print("=" * 60)
    print("üéØ MBA Job Hunter - Indeed Scraper System Demo")
    print("=" * 60)
    print()

async def demo_scraper_creation():
    """Demonstrate scraper creation and configuration."""
    print("üìã 1. Scraper Creation & Configuration")
    print("-" * 40)
    
    # Basic scraper
    scraper = IndeedScraper()
    print(f"‚úÖ Created {scraper.name} scraper")
    print(f"   - Base URL: {scraper.base_url}")
    print(f"   - Scraper Type: {scraper.scraper_type}")
    
    # Custom configuration
    config = ScrapingConfig(
        max_pages=5,
        delay_between_requests=1.5,
        rate_limit_per_minute=20,
        timeout_seconds=30
    )
    
    custom_scraper = IndeedScraper(config)
    print(f"‚úÖ Created custom configured scraper")
    print(f"   - Max pages: {custom_scraper.config.max_pages}")
    print(f"   - Rate limit: {custom_scraper.config.rate_limit_per_minute}/min")
    print()

async def demo_search_url_building():
    """Demonstrate search URL building."""
    print("üìã 2. Search URL Building")
    print("-" * 40)
    
    scraper = IndeedScraper()
    
    # Basic search
    params = scraper._build_search_params("Product Manager", "San Francisco")
    print("‚úÖ Basic search parameters:")
    for key, value in params.items():
        print(f"   - {key}: {value}")
    
    # Advanced search
    advanced_params = scraper._build_search_params(
        "Business Analyst",
        "New York",
        salary_min=80000,
        job_type="full_time",
        remote_only=True,
        experience_level="mid_level"
    )
    
    from urllib.parse import urlencode
    search_url = f"{scraper._base_search_url}?{urlencode(advanced_params)}"
    print(f"\n‚úÖ Advanced search URL generated:")
    print(f"   {search_url}")
    print()

async def demo_data_processing():
    """Demonstrate data processing utilities."""
    print("üìã 3. Data Processing & Utilities")
    print("-" * 40)
    
    # Location normalization
    test_locations = ["sf", "nyc", "remote", "Seattle, WA"]
    print("‚úÖ Location normalization:")
    for loc in test_locations:
        normalized = location_normalizer.normalize_location(loc)
        print(f"   - '{loc}' ‚Üí '{normalized}'")
    
    # Skills extraction
    job_description = """
    Product Manager position requiring MBA background.
    Must have experience with SQL, Python, and Tableau.
    Strong project management and leadership skills required.
    Experience with Agile methodology preferred.
    """
    
    skills = skill_extractor.extract_skills(job_description)
    print(f"\n‚úÖ Skills extraction from job description:")
    print(f"   - Found {len(skills)} skills: {skills[:8]}")
    
    # Job data validation
    valid_job = {
        "title": "Senior Product Manager",
        "company_name": "Tech Corp",
        "description": "We are seeking a dynamic Product Manager with MBA background...",
        "location": "San Francisco, CA",
        "source": "indeed"
    }
    
    is_valid = await validate_job_data(valid_job)
    relevance_score = calculate_job_relevance_score(valid_job)
    
    print(f"\n‚úÖ Job data validation & scoring:")
    print(f"   - Validation passed: {is_valid}")
    print(f"   - MBA relevance score: {relevance_score:.2f}")
    print()

async def demo_scraper_manager():
    """Demonstrate scraper manager functionality."""
    print("üìã 4. Scraper Manager")
    print("-" * 40)
    
    manager = ScraperManager()
    
    # Register scrapers
    indeed_scraper = IndeedScraper()
    manager.register_scraper(indeed_scraper)
    
    print("‚úÖ Scraper manager initialized:")
    print(f"   - Registered scrapers: {list(manager.scrapers.keys())}")
    
    # Show stats
    stats = manager.get_stats()
    print(f"   - Initial stats: {stats}")
    print()

async def demo_job_data_structure():
    """Demonstrate JobData structure."""
    print("üìã 5. Job Data Structure")
    print("-" * 40)
    
    # Create sample job data
    job = JobData(
        title="Product Manager - MBA Required",
        company_name="Innovative Tech Solutions",
        location="San Francisco, CA",
        description="Leading product strategy for our SaaS platform...",
        requirements="MBA required, 3+ years PM experience",
        salary_min=120000,
        salary_max=180000,
        salary_currency="USD",
        salary_period="annual",
        job_type="Full-time",
        experience_level="Mid Level",
        source="indeed",
        source_url="https://indeed.com/viewjob?jk=example123",
        skills_required=["MBA", "Product Management", "Strategy", "SQL"],
        is_remote=False,
        posted_date=None
    )
    
    print("‚úÖ Sample JobData object created:")
    print(f"   - Title: {job.title}")
    print(f"   - Company: {job.company_name}")
    print(f"   - Location: {job.location}")
    print(f"   - Salary Range: ${job.salary_min:,} - ${job.salary_max:,}")
    print(f"   - Skills: {job.skills_required}")
    print(f"   - Remote: {job.is_remote}")
    print()

async def demo_error_handling():
    """Demonstrate error handling capabilities."""
    print("üìã 6. Error Handling & Rate Limiting")
    print("-" * 40)
    
    scraper = IndeedScraper()
    
    # Test rate limiting
    print("‚úÖ Rate limiting demonstration:")
    start_time = asyncio.get_event_loop().time()
    
    for i in range(3):
        await scraper._rate_limit_check()
        print(f"   - Rate limit check {i+1} completed")
    
    elapsed = asyncio.get_event_loop().time() - start_time
    print(f"   - Total time: {elapsed:.3f} seconds")
    
    # Show configuration
    print(f"   - Configured delay: {scraper.config.delay_between_requests}s")
    print(f"   - Rate limit: {scraper.config.rate_limit_per_minute}/min")
    print()

async def demo_user_agent_rotation():
    """Demonstrate user agent rotation."""
    print("üìã 7. Anti-Detection Features")
    print("-" * 40)
    
    scraper = IndeedScraper()
    
    print("‚úÖ User agent rotation:")
    print(f"   - Available user agents: {len(scraper._user_agents)}")
    print(f"   - Sample user agent: {scraper._user_agents[0][:50]}...")
    
    print("\n‚úÖ MBA job relevance filtering:")
    
    # Test relevance filtering
    relevant_job = JobData(
        title="Product Manager",
        company_name="Tech Co",
        description="MBA preferred, strategy and analytics",
        source="indeed"
    )
    
    irrelevant_job = JobData(
        title="Warehouse Worker",
        company_name="Logistics Co", 
        description="Physical labor, no degree required",
        source="indeed"
    )
    
    print(f"   - Relevant job passes filter: {scraper._is_relevant_job(relevant_job)}")
    print(f"   - Irrelevant job filtered out: {not scraper._is_relevant_job(irrelevant_job)}")
    print()

def show_summary():
    """Show system capabilities summary."""
    print("üìä System Capabilities Summary")
    print("-" * 40)
    print("‚úÖ Core Features:")
    print("   ‚Ä¢ Indeed job scraping with anti-detection")
    print("   ‚Ä¢ Configurable rate limiting and delays")
    print("   ‚Ä¢ Advanced search parameter building")
    print("   ‚Ä¢ MBA-focused job relevance filtering")
    print("   ‚Ä¢ Comprehensive error handling")
    print()
    print("‚úÖ Data Processing:")
    print("   ‚Ä¢ Location standardization")
    print("   ‚Ä¢ Skills extraction (17 skill categories)")
    print("   ‚Ä¢ Salary parsing and normalization")
    print("   ‚Ä¢ Job data validation")
    print("   ‚Ä¢ Relevance scoring for MBA roles")
    print()
    print("‚úÖ Architecture:")
    print("   ‚Ä¢ Abstract base scraper class")
    print("   ‚Ä¢ Modular utility functions")
    print("   ‚Ä¢ Async/await support")
    print("   ‚Ä¢ Comprehensive configuration system")
    print("   ‚Ä¢ Multi-scraper management")
    print()
    print("üöÄ Ready for Production!")
    print("   The scraper system is fully functional and ready to")
    print("   integrate with your job hunting application.")
    print()

async def main():
    """Run the complete demonstration."""
    print_banner()
    
    try:
        await demo_scraper_creation()
        await demo_search_url_building()
        await demo_data_processing()
        await demo_scraper_manager()
        await demo_job_data_structure()
        await demo_error_handling()
        await demo_user_agent_rotation()
        
        show_summary()
        
        print("üéâ All demonstrations completed successfully!")
        print("The Indeed scraper system is ready for use.")
        
    except Exception as e:
        print(f"‚ùå Demo failed with error: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)