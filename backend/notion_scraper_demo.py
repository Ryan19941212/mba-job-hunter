#!/usr/bin/env python3
"""
Complete Notion + Scraper Integration Demo

Demonstrates the full workflow from job scraping to Notion database creation
and data synchronization for the MBA Job Hunter application.
"""

import asyncio
import sys
import os
from datetime import datetime, timezone
from typing import List, Dict
import random

# Add the app directory to Python path  
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app'))

from services.notion_writer import NotionWriter
from scrapers.indeed import IndeedScraper
from scrapers.base import JobData, ScrapingConfig
from scrapers.utils import calculate_job_relevance_score

def print_banner():
    """Print demo banner."""
    print("ğŸ¯" + "=" * 58 + "ğŸ¯")
    print("ğŸš€ MBA Job Hunter: Notion + Scraper Integration Demo")
    print("ğŸ¯" + "=" * 58 + "ğŸ¯")
    print()

async def demo_notion_database_setup():
    """Demo Notion database setup and schema."""
    print("ğŸ“‹ 1. Notion Database Setup")
    print("-" * 40)
    
    # Check for API key
    api_key = os.getenv("NOTION_API_KEY")
    if not api_key:
        print("âš ï¸  NOTION_API_KEY not set - using demo mode")
        api_key = "dummy_key_for_demo"
    
    try:
        async with NotionWriter(api_key=api_key) as writer:
            # Test database schema
            schema = writer._get_database_properties_schema()
            
            print(f"âœ… Generated database schema with {len(schema)} properties")
            
            # Show key properties
            key_props = [
                "Job Title", "Company", "Location", "Salary Min", "Salary Max",
                "Application Status", "MBA Relevance", "AI Fit Score"
            ]
            
            print("ğŸ—ï¸ Key database properties:")
            for prop in key_props:
                if prop in schema:
                    prop_type = list(schema[prop].keys())[0]
                    print(f"   â€¢ {prop}: {prop_type}")
            
            # Test connection if real API key
            if api_key != "dummy_key_for_demo":
                connection_ok = await writer.test_connection()
                if connection_ok:
                    print("âœ… Notion API connection successful!")
                    
                    # Try to get or create database
                    try:
                        database_id = await writer.get_or_create_database("MBA Job Hunter Demo")
                        print(f"âœ… Database ready: {database_id}")
                        return database_id
                    except Exception as e:
                        print(f"âš ï¸  Database setup failed: {e}")
                else:
                    print("âŒ Notion API connection failed")
            else:
                print("ğŸ“ Demo mode - no real API calls made")
            
    except Exception as e:
        print(f"âŒ Setup failed: {e}")
    
    print()
    return None

async def demo_job_scraping_simulation():
    """Demo job scraping (simulated data)."""
    print("ğŸ“‹ 2. Job Scraping Simulation")
    print("-" * 40)
    
    try:
        # Create scraper configuration
        config = ScrapingConfig(
            max_pages=2,
            delay_between_requests=1.0,
            rate_limit_per_minute=20
        )
        
        scraper = IndeedScraper(config)
        
        print(f"âœ… Created Indeed scraper:")
        print(f"   â€¢ Name: {scraper.name}")
        print(f"   â€¢ Base URL: {scraper.base_url}")
        print(f"   â€¢ Type: {scraper.scraper_type}")
        
        # Generate sample job data (simulating scraped jobs)
        sample_jobs = []
        
        job_templates = [
            {
                "title": "Senior Product Manager - MBA Required",
                "company_name": "Google",
                "location": "Mountain View, CA",
                "description": "Lead product strategy for our AI platform. Work with cross-functional teams to define product roadmap and drive growth initiatives. MBA from top-tier school required.",
                "requirements": "â€¢ MBA from top business school\nâ€¢ 5+ years product management experience\nâ€¢ Strong analytical and strategic thinking skills\nâ€¢ Experience with data-driven decision making",
                "salary_min": 150000,
                "salary_max": 220000,
                "job_type": "Full-time",
                "experience_level": "Senior Level",
                "skills_required": ["MBA", "Product Management", "Strategy", "Analytics", "Leadership"]
            },
            {
                "title": "Management Consultant",
                "company_name": "McKinsey & Company",
                "location": "New York, NY", 
                "description": "Work with Fortune 500 clients on strategic initiatives. Conduct market analysis, develop business cases, and present recommendations to C-level executives.",
                "requirements": "â€¢ MBA from top-tier program\nâ€¢ 2+ years consulting experience\nâ€¢ Strong problem-solving skills\nâ€¢ Excellent communication abilities",
                "salary_min": 165000,
                "salary_max": 200000,
                "job_type": "Full-time",
                "experience_level": "Mid Level",
                "skills_required": ["MBA", "Consulting", "Strategy", "Financial Modeling", "Presentation"]
            },
            {
                "title": "Business Development Manager",
                "company_name": "Salesforce",
                "location": "San Francisco, CA",
                "description": "Drive business growth through strategic partnerships and client relationships. Identify new market opportunities and develop go-to-market strategies.",
                "requirements": "â€¢ MBA preferred\nâ€¢ 3+ years business development experience\nâ€¢ Strong relationship building skills\nâ€¢ Experience in SaaS industry",
                "salary_min": 120000,
                "salary_max": 160000,
                "job_type": "Full-time", 
                "experience_level": "Mid Level",
                "skills_required": ["MBA", "Business Development", "Sales", "Strategy", "Communication"]
            },
            {
                "title": "Strategy Analyst",
                "company_name": "Amazon",
                "location": "Seattle, WA",
                "description": "Support strategic planning initiatives across business units. Conduct competitive analysis, financial modeling, and market research to inform key business decisions.",
                "requirements": "â€¢ MBA or advanced degree\nâ€¢ Strong analytical skills\nâ€¢ Proficiency in Excel and SQL\nâ€¢ Experience with data visualization tools",
                "salary_min": 110000,
                "salary_max": 140000,
                "job_type": "Full-time",
                "experience_level": "Entry Level",
                "skills_required": ["MBA", "Strategy", "Analytics", "SQL", "Financial Modeling"]
            },
            {
                "title": "Operations Manager",
                "company_name": "Apple",
                "location": "Cupertino, CA",
                "description": "Lead operational excellence initiatives and process improvements. Manage cross-functional projects to optimize supply chain and manufacturing operations.",
                "requirements": "â€¢ MBA in Operations or related field\nâ€¢ 4+ years operations experience\nâ€¢ Lean/Six Sigma certification preferred\nâ€¢ Strong project management skills",
                "salary_min": 130000,
                "salary_max": 170000,
                "job_type": "Full-time",
                "experience_level": "Senior Level", 
                "skills_required": ["MBA", "Operations Management", "Process Improvement", "Project Management", "Lean"]
            }
        ]
        
        # Create JobData objects
        for i, template in enumerate(job_templates):
            job_data = JobData(
                title=template["title"],
                company_name=template["company_name"],
                location=template["location"],
                description=template["description"],
                requirements=template["requirements"],
                salary_min=template["salary_min"],
                salary_max=template["salary_max"],
                salary_currency="USD",
                salary_period="annual",
                job_type=template["job_type"],
                experience_level=template["experience_level"],
                source="indeed",
                source_job_id=f"job_{i+1}",
                source_url=f"https://indeed.com/viewjob?jk=sample_{i+1}",
                skills_required=template["skills_required"],
                is_remote=random.choice([True, False]),
                posted_date=datetime.now(timezone.utc)
            )
            
            # Convert to dict for processing
            job_dict = {
                "title": job_data.title,
                "company_name": job_data.company_name,
                "location": job_data.location,
                "description": job_data.description,
                "requirements": job_data.requirements,
                "salary_min": job_data.salary_min,
                "salary_max": job_data.salary_max,
                "salary_currency": job_data.salary_currency,
                "job_type": job_data.job_type,
                "experience_level": job_data.experience_level,
                "source": job_data.source,
                "source_url": job_data.source_url,
                "skills_required": job_data.skills_required,
                "is_remote": job_data.is_remote,
                "posted_date": job_data.posted_date
            }
            
            # Calculate relevance score
            job_dict["relevance_score"] = calculate_job_relevance_score(job_dict)
            
            sample_jobs.append(job_dict)
        
        print(f"âœ… Generated {len(sample_jobs)} sample jobs")
        
        # Show job summary
        for i, job in enumerate(sample_jobs, 1):
            relevance = job["relevance_score"]
            relevance_label = "High" if relevance >= 0.7 else "Medium" if relevance >= 0.4 else "Low"
            
            print(f"   {i}. {job['title']} at {job['company_name']}")
            print(f"      ğŸ’° ${job['salary_min']:,} - ${job['salary_max']:,}")
            print(f"      ğŸ¯ MBA Relevance: {relevance:.2f} ({relevance_label})")
        
        print()
        return sample_jobs
        
    except Exception as e:
        print(f"âŒ Scraping simulation failed: {e}")
        print()
        return []

async def demo_notion_integration(jobs_data: List[Dict], database_id: str = None):
    """Demo Notion integration with scraped jobs."""
    print("ğŸ“‹ 3. Notion Integration Demo")
    print("-" * 40)
    
    if not jobs_data:
        print("âš ï¸  No job data available for Notion integration")
        print()
        return
    
    api_key = os.getenv("NOTION_API_KEY", "dummy_key_for_demo")
    
    try:
        async with NotionWriter(api_key=api_key, database_id=database_id) as writer:
            print(f"âœ… Notion writer initialized")
            
            # Format jobs for Notion
            formatted_jobs = []
            
            print("ğŸ”„ Formatting jobs for Notion...")
            for i, job in enumerate(jobs_data, 1):
                try:
                    formatted = await writer.format_job_for_notion(job)
                    formatted_jobs.append(formatted)
                    
                    # Show formatting details
                    properties = formatted.get("properties", {})
                    children = formatted.get("children", [])
                    
                    print(f"   {i}. {job['title']}")
                    print(f"      ğŸ“Š Properties: {len(properties)}")
                    print(f"      ğŸ“„ Content blocks: {len(children)}")
                    
                except Exception as e:
                    print(f"   âŒ Failed to format job {i}: {e}")
            
            print(f"âœ… Successfully formatted {len(formatted_jobs)} jobs")
            
            # Demo batch processing
            if api_key != "dummy_key_for_demo":
                print("\nğŸš€ Starting batch write to Notion...")
                try:
                    page_ids = await writer.batch_write_jobs(jobs_data)
                    print(f"âœ… Successfully created {len(page_ids)} job pages")
                    
                    # Show statistics
                    stats = writer.get_stats()
                    print(f"\nğŸ“Š Notion Writer Statistics:")
                    print(f"   â€¢ Jobs written: {stats['jobs_written']}")
                    print(f"   â€¢ Jobs updated: {stats['jobs_updated']}")
                    print(f"   â€¢ Errors: {stats['errors']}")
                    print(f"   â€¢ Last sync: {stats['last_sync']}")
                    
                except Exception as e:
                    print(f"âŒ Batch write failed: {e}")
            else:
                print("ğŸ“ Demo mode - jobs formatted but not written to Notion")
                print("   Set NOTION_API_KEY environment variable for real integration")
    
    except Exception as e:
        print(f"âŒ Notion integration failed: {e}")
    
    print()

async def demo_end_to_end_workflow():
    """Demo complete end-to-end workflow."""
    print("ğŸ“‹ 4. End-to-End Workflow Demo")
    print("-" * 40)
    
    print("ğŸ”„ Simulating complete MBA job hunting workflow:")
    print()
    
    # Step 1: Initialize services
    print("1ï¸âƒ£ Initializing services...")
    api_key = os.getenv("NOTION_API_KEY", "dummy_key_for_demo")
    
    config = ScrapingConfig(
        max_pages=3,
        delay_between_requests=1.0,
        rate_limit_per_minute=30
    )
    
    scraper = IndeedScraper(config)
    
    print("   âœ… Scraper configured")
    print("   âœ… Notion writer ready")
    
    # Step 2: Search parameters
    print("\n2ï¸âƒ£ Setting up job search parameters...")
    search_queries = ["Product Manager", "Business Analyst", "Strategy Consultant"]
    locations = ["San Francisco", "New York", "Remote"]
    
    for query in search_queries:
        for location in locations:
            params = scraper._build_search_params(query, location, salary_min=100000)
            from urllib.parse import urlencode
            url = f"{scraper.base_url}/jobs?{urlencode(params)}"
            print(f"   ğŸ“‹ {query} in {location}")
    
    print("   âœ… Search parameters configured")
    
    # Step 3: Simulate data processing pipeline
    print("\n3ï¸âƒ£ Processing job data pipeline...")
    
    # Sample job for pipeline demo
    sample_job = {
        "title": "Senior Product Manager - MBA Program",
        "company_name": "Tech Innovators Inc",
        "location": "San Francisco, CA",
        "description": "Lead product strategy for our fintech platform. MBA from top program required.",
        "salary_min": 140000,
        "salary_max": 180000,
        "source": "indeed",
        "source_url": "https://indeed.com/viewjob?jk=pipeline_demo",
        "skills_required": ["MBA", "Product Management", "Strategy", "Fintech", "Leadership"]
    }
    
    # Step 3a: Calculate relevance
    relevance = calculate_job_relevance_score(sample_job)
    sample_job["relevance_score"] = relevance
    print(f"   ğŸ“Š MBA relevance calculated: {relevance:.2f}")
    
    # Step 3b: Format for Notion
    async with NotionWriter(api_key=api_key) as writer:
        formatted = await writer.format_job_for_notion(sample_job)
        properties_count = len(formatted.get("properties", {}))
        blocks_count = len(formatted.get("children", []))
        
        print(f"   ğŸ”„ Formatted for Notion: {properties_count} properties, {blocks_count} blocks")
        
        # Step 3c: Simulate duplicate check
        existing_page = await writer.find_existing_job(sample_job["source_url"])
        if existing_page:
            print(f"   ğŸ” Found existing job: {existing_page}")
        else:
            print("   ğŸ†• New job detected")
        
        print("   âœ… Pipeline processing complete")
    
    # Step 4: Show integration benefits
    print("\n4ï¸âƒ£ Integration benefits:")
    print("   ğŸ¯ Automated MBA relevance scoring")
    print("   ğŸ“Š Rich Notion database with structured data")
    print("   ğŸ”„ Duplicate detection and updates")
    print("   ğŸ“ˆ Application tracking and status management")
    print("   ğŸ¨ Beautiful job descriptions with formatting")
    print("   ğŸ·ï¸ Skill tagging and categorization")
    
    print("\nâœ… End-to-end workflow demonstration complete!")
    print()

def show_setup_instructions():
    """Show setup instructions for users."""
    print("ğŸ“‹ 5. Setup Instructions")
    print("-" * 40)
    
    print("ğŸš€ To use the complete MBA Job Hunter system:")
    print()
    
    print("1ï¸âƒ£ Notion Setup:")
    print("   â€¢ Go to https://www.notion.so/my-integrations")
    print("   â€¢ Create a new integration")
    print("   â€¢ Copy the API key")
    print("   â€¢ Set NOTION_API_KEY environment variable")
    print()
    
    print("2ï¸âƒ£ Environment Configuration:")
    print("   â€¢ Create .env file in backend directory")
    print("   â€¢ Add: NOTION_API_KEY=your_api_key_here")
    print("   â€¢ Optionally add: NOTION_DATABASE_ID=existing_database_id")
    print()
    
    print("3ï¸âƒ£ Run the System:")
    print("   â€¢ python3 notion_scraper_demo.py")
    print("   â€¢ The system will create a database if none exists")
    print("   â€¢ Jobs will be automatically scraped and added to Notion")
    print()
    
    print("4ï¸âƒ£ Notion Database Features:")
    print("   â€¢ ğŸ“ Job title, company, location, description")
    print("   â€¢ ğŸ’° Salary range with currency support")  
    print("   â€¢ ğŸ¯ MBA relevance scoring (High/Medium/Low)")
    print("   â€¢ ğŸ“Š AI fit score and analysis")
    print("   â€¢ ğŸ·ï¸ Skills tagging and requirements")
    print("   â€¢ ğŸ“‹ Application status tracking")
    print("   â€¢ ğŸ“… Posted dates and deadlines")
    print("   â€¢ ğŸ¢ Company information and logos")
    print()
    
    print("5ï¸âƒ£ Workflow Integration:")
    print("   â€¢ ğŸ” Scrape jobs from Indeed (and other boards)")
    print("   â€¢ ğŸ¯ Automatically score MBA relevance")
    print("   â€¢ ğŸ“Š Create rich Notion pages with formatted content")
    print("   â€¢ ğŸ”„ Handle duplicates and updates intelligently")
    print("   â€¢ ğŸ“ˆ Track application progress")
    print("   â€¢ ğŸ¨ Beautiful, organized job database")
    print()

async def main():
    """Run the complete Notion + Scraper integration demo."""
    print_banner()
    
    try:
        # Demo components
        database_id = await demo_notion_database_setup()
        jobs_data = await demo_job_scraping_simulation()
        await demo_notion_integration(jobs_data, database_id)
        await demo_end_to_end_workflow()
        show_setup_instructions()
        
        print("ğŸ‰ Notion + Scraper Integration Demo Complete!")
        print("ğŸš€ Your MBA Job Hunter system is ready to use!")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        return False
    
    return True

if __name__ == "__main__":
    asyncio.run(main())